 
                            +-=-=-=-=-=-=-=-=-=-+
                            | E . S . S . E . X |
                            +-=-=-=-=-=-=-=-=-=-+

                                   - is - 
			 
              (E)fficient (S)calable (S)earch (E)ngine for (X)ML


                   (c) 2002-2003 Aaron Krowne, Virginia Tech 


                               (rev. 20031016)

by Aaron Krowne (akrowne@vt.edu)

 at the Virginia Tech Digital Library Research Lab

Code contributors:

- Kevin Ferguson (daemonization, stemmer, socket code)
- Pavel Calado (structured query inference)
- Matthew Gracey (initial search engine implementation)

Testing:

- Ming Luo

Permanent contact: Dr. Edward A. Fox (fox@vt.edu).

About
=====

ESSEX is a search engine which is meant to meet the capabilities of ODL-IRDB
v 1.1 so as to power an "equivalent" ODL component. This means it can be used
as the underlying engine for XML records, and it has the same end-user search 
capabilities as IRDB (more on this in the next section).

Over IRDB, ESSEX subtracts reliance on an external DBMS, adds high speed
(through the C++ implementation and in-memory architecture), adds massive
scalability, and adds adjustable field weight ranking. Additionally, ESSEX is
able to automatically build structured queries, given a plain set of keywords.

For more on the scalability, A standard desktop machine with 1GB of RAM should
easily be able to run ESSEX with a million metadata records (note that 
"metadata" is much smaller than full text, but about the same size as your 
standard web page.  On the other hand, nobody indexes past the first one or
two pages of full text anyway...).

ESSEX runs as a stand-alone daemon which communicates over sockets to a client,
written in any language whatsoever.

Features
========

- In-memory engine.  (Why? RAM is cheap!)
- Fast indexing.
- Fast unindexing/updates (distinct improvement over IRDB).
- Fast searching.
- Force/forbid (+/-) specifiers on query terms.
- Field filters on query terms (e.g. "author:knuth").
- Field weights are adjustable (e.g. "LaTeX abstract=1 title=5").
- Automatic query structuring (e.g. a simple query like "knuth tex", can become "author:knuth title:tex", without user intervention).
- Unix domain and TCP socket architecture.
- Comes with Perl client module.
- Multithreaded.
- Platform-independent (among POSIX systems). (Well, this is untested actually.)
- Memory locking to prevent swapping when run as root (under Linux).

Installing
==========

1. Untar.  
2. Inspect/modify config.h. 
3. Take a look at "make" in server/.  It handles Linux and BSD, but could 
   possibly break in some variants.  If you don't have bash and/or g++ on your 
   platform, you'll have to improvise (but the code /should/ compile in a 
   standard setting).
4. Run ./make (or equivalent)
5. Configure essex.conf.
6. The daemon is "essexd"; run this to start it.

Interfacing With Your System
============================

If your system is Perl, you may simply utilize SearchClient.pm.  Check out the
files in the sample/ subdir to see how this is done.

Otherwise, there are no pre-prepared client modules.  You can roll your own 
based on SearchClient.pm.  Please let us know if you write one, we'd like to
include it in future distributions for the benefit of others.

Query Syntax
============

Queries are of the form:

 (('+'|'-')?(field:)?term|field=weight)( ('+'|'-')?(field:)?term| field=weight)*

Where

 - 'field' is one of the metadata fields that was indexed.
 - 'term' is any word being searched for
 - 'weight' is a floating point number

The capabilities this allows are:

 - field:term to restrict occurrences of 'term' to the field 'field'.
 - '+' and '-' operators to force occurrences to appear in resulting documents
   or to be absent, respectively.
 - field=weight to scale the importance of field 'field' to 'weight'.  

Field weighting is a relative notion.  The default field weight is 1.  If you
set a single weight to something greater than 1, but do not specify any others,
as in the query :

    LaTeX title=5

behind-the-scenes, all of the other fields will become worth 1/5, and title 
will become worth 1.   

Query Structuring
=================

ESSEX is able to guess the correct structure for plain keyword-based
queries. Given a set of keywords, ESSEX will return all the possible structured
queries, sorted by the probability of being the correct field/attribute
assignments based on the database contents.

For instance, given the keywords "knuth tex 1970", ESSEX would return
(depending on the data stored):

    0.95 author:knuth title:tex year:1970
    0.84 author:knuth abstract:tex year:1970
    0.53 abstract:knuth abstract:tex year:1970
    ...

Any of the returned queries can then be submitted to the search
engine. Automatic query structuring is a useful feature that allows improved
precision in the search results.

Drawbacks
=========

Due to the in-memory-only architecture, you must re-index your collection 
between reboots or crashes.   This should take around 10 minutes for about
100,000 records on a 2 GHz machine.  Clearly, for small collections, this 
start-up time will be negligible.  We hope to fix this soon by adding a disk
image of the index.

 NOTE: If indexing is slow, it is almost certain ESSEX is not the reason.  If 
 you are drawing information from a database, the more scattered the data you 
 are gathering, the longer this will take.  If speed is imperative, it is better
 to gather your data and put it in a flat file, then use this for indexing.

By default, ESSEX is set up for "extreme" compression of search engine data 
structures, and the following limits hold:

- 16.7 million documents
- 16 distinct metadata fields (or distinct XML elements)
- 16 distinct term counts per element (i.e. word counts are only stored as 
  a number from 1 to 16; anything higher than 16 is stored as 16).

The term count should not be a serious problem for IR.  The document limit 
also should not a problem; we mean ESSEX to be scalable, but it is no 
Google(tm).  

The metadata field limit is potentially more serious.  This means for indexing 
XML documents, you cannot willy-nilly throw anything into ESSEX.  You have to
be  somewhat selective about which portions of the XML to index.  And really, 
you  should only be indexing fields that end-users care about, so it is almost
always the case that some transform should be applied to the raw record XML to 
produce smaller indexable XML.   Thus we don't consider this to really be any
extra work.

If you aren't indexing XML, you probably won't view this as a major restriction 
its hard to think of more than 16 useful fields anyway (Dublin Core only has 15).  Remember, inasmuch as fields are not distinguishable to the end user in 
terms of query field restrictions, you can just concatenate fields into larger
blobs (for example, you'd probably want to concatenate source fields "author1",
"author2", "author3", etc, into just "author" for both ESSEX's and the end 
user's convenience.

We think the limits above are reasonable for most non-capital-intensive
applications.  Howver, you can extend them by defining RELAX_POSTINGS in 
config.h.  This will increase the document limit to 4 billion, the term count 
limit per tag to 256, and the tag count to 256.  However, ESSEX will take from
50-100% more memory.

TODO (roughly in order of importance)
====

- (easy to fix) There is a bug in the protocol-- if you have a document ID with
  a numeric ID which is the same as the "no more search results" connection 
  code, then you could lose search results.  One way to fix this is to terminate
  the search results with a blank line, another would be to give the number of
  results first, before the results themselves.

- Add disk-image to bypass re-indexing, complete with buffering and log 
  playback.  Portions of this code are hanging around, commented out, from 
  a much older version of this system.

- Finish "compactify" routine so that it re-numbers all identifiers to free 
  slots used by items that have since been removed.  Until this is done, there
  may be a risk of needing to restart occasionally for very, very frequent
  updates (not new additions) to the index.

- Figure out if we can do anything to explicitly return unused heap memory
  to the OS. (Would be very, very useful for compactify).

- Change the way term counts are interpreted so that the 16 distinct levels 
  are a progressive scale by 1s, 2s, and so on, which will let us store counts 
  from 1 to 60.

- Do a radix sort for rankings at the end of search routine, rather than the 
  STL introsort. 

- Rewrite the core of vector_search::search.  The way the document vectors  
  are handled (implicitly) is legacy design; this should really be reorganized
  to use intmaps (which are more like "real" vectors).

- Put XML traversing and indexing code in the SearchClient module, or in a 
  separate script that utilizes it.

- Explore feasibility of stemmed/unstemmed fusion (I've never heard of anyone 
  doing this).  What this would do is index document terms unstemmed, and 
  instead of stemming query terms, expand each term /backwards/ to every known
  unstemmed word which can lead to the same stem (in other words, to the
  equivalence class of the query word under stemming).  Then this expanded 
  query would be applied, but with the *original* term weighted higher.  This 
  would (likely) have the same recall as normal stemming, but a higher 
  precision, since users would have more expressive power due to the 
  distinction between query terms and other terms in the same stemmed 
  equivalence class.  This is based on the intuition that it seems wrong for
  stemming to place morphological variants in as high weighting as the verbatim
  query, yet we don't want to lose the recall benefit they yield.

- It would be nice to combine the intmap and stringmap classes, but I don't 
  know enough about C++ templates to know how to manage this (somehow at 
  compile-time we have to select between method implementations!).

- Adaptive dimensionality reduction?

- Tweak data structures based on empirical values derived from runs with 
  varying query and collection sizes.

- Stop using string class in stringmaps; use char arrays for efficiency?

- Share actual strings in memory between the docid map and reverse map.
  (Might save a few MB).

- Take over vector allocation in stringmaps (the same as was done for intmaps) 
  (Might save a few KB).

TODO (Completed!)
=================

- Decomposition of vector_search::search into subroutines for clarity.

- Put in an anti-swap memory polling thread.

- There are some robustness issues in the socket communication; if the client
  breaks off at the wrong time, the entire daemon will come crashing down.  
  This really needs to be fixed.

- Add configurable field weightings.

